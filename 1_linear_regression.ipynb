{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why modelling data?\n",
    "\n",
    "<img src=\"figures/data-science-model.png\" width=\"500px\" heigth=\"500px\">\n",
    "\n",
    "*What is modelling?*\n",
    "\n",
    "A statistical model is a mathematical model (i.e., a description of a system or process expressed in mathematical terms), typically specified as a relationship between input variables (or features, or independent variables) and an output (dependent) variable. Given a model or a family of models, data are used to find good configurations of it via training or fitting (i.e., ending with a configuration such that the output variable is predicted well from the input variables).\n",
    "\n",
    "*Why modelling?*\n",
    "\n",
    "Statistical models are used for:\n",
    "* Prediction: based on past data, we fit a model, which we use to predict on future data. This is the primary objective of Machine Learning.\n",
    "* Inspection: we use some data to fit a model and inspect it, in order to understand how different variables interact and contribute to the prediction of the output.\n",
    "\n",
    "Note that statistical or data-driven modelling, which attempts to summarize or describe some existing observations, is not the only way to model. Theory-driven modelling can be used instead, by formalizing a certain understanding of a system into theory taking mathematical form, such as we do in physics, and then testing its predictions via observation or experiment.\n",
    "\n",
    "For more see:\n",
    "* https://hdsr.mitpress.mit.edu/pub/9qsbf3hz\n",
    "* http://www2.math.uu.se/~thulin/mm/breiman.pdf\n",
    "\n",
    "Topics:\n",
    "1. Linear regression model\n",
    "2. Closed-form analytic solution\n",
    "3. Stochastic Gradient Descent solution\n",
    "4. Implementations\n",
    "5. Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os, codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model\n",
    "\n",
    "* **Regression**: predict real/continuous values given inputs (e.g., a salary of 2.15 ducats a year).\n",
    "* **Classification**: predict categorical values given inputs (e.g., is there a female guarantor in the contract or not).\n",
    "\n",
    "Model (3.1.2):\n",
    "\n",
    "$y = \\sum_{j=1}^{d}w_j x_j + b$\n",
    "\n",
    "Or, in matrix form (3.1.4):\n",
    "\n",
    "$y = Xw + b$\n",
    "\n",
    "**Closed-form analytic solution** (3.1.9), where we merge $b$ into $w$:\n",
    "\n",
    "$w = \\Big(X^TX\\Big)^{-1}X^Ty$\n",
    "\n",
    "And new predictions are done as follows:\n",
    "\n",
    "$\\hat{y} = w^Tx$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a toy example\n",
    "\n",
    "mean = [0, 0] # means (centers of mass)\n",
    "cov = [[5, 0], [120, 100]]  # covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x, y = np.random.multivariate_normal(mean, cov, 1000, check_valid='ignore').T\n",
    "plt.plot(x, y, 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit a linear model to the data at hand\n",
    "\n",
    "beta = 1/(np.dot(x.T,x)) * np.dot(x.T,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta # in this 2d example this is just the slope of the line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point = 15\n",
    "y_hat = beta * new_point\n",
    "plt.plot(x, y, 'x')\n",
    "plt.plot(new_point, y_hat, 'o', c='red')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.arange(-40,40,0.5)\n",
    "predictions = beta * new_points\n",
    "plt.plot(x, y, 'x')\n",
    "plt.plot(new_points, predictions, '.', c='red')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add an outlier\n",
    "\n",
    "x[0] = 200\n",
    "plt.plot(x, y, 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit a linear model to the data again\n",
    "\n",
    "beta = 1/(np.dot(x.T,x)) * np.dot(x.T,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.arange(-40,40,0.5)\n",
    "predictions = beta * new_points\n",
    "plt.plot(x, y, 'x')\n",
    "plt.plot(new_points, predictions, '.', c='red')\n",
    "plt.axis('equal')\n",
    "plt.xlim((-40,40))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example with the intercept\n",
    "\n",
    "mean = [0, 15] # means (centers of mass)\n",
    "cov = [[5, 0], [120, 100]]  # covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.random.multivariate_normal(mean, cov, 1000, check_valid='ignore').T\n",
    "plt.plot(x, y, 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit a linear model to the data at hand\n",
    "\n",
    "beta = 1/(np.dot(x.T,x)) * np.dot(x.T,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.arange(-40,40,0.5)\n",
    "predictions = beta * new_points\n",
    "plt.plot(x, y, 'x')\n",
    "plt.plot(new_points, predictions, '.', c='red')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not work any longer, as the default intercept is at 0,0. We need to fit for the intercept as well as for the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a trick and add a new column to x, all to 1: this will allow us to fit for the intercept as well\n",
    "\n",
    "X = np.matrix([np.ones(x.shape[0]),x]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as above, but we need a little bit more machinery to deal with matrices\n",
    "\n",
    "betas = np.dot(np.linalg.inv(np.dot(X.T,X)),np.dot(X.T,y).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.arange(-40,40,0.5)\n",
    "predictions = betas[1,0] * new_points\n",
    "plt.plot(x, y, 'x')\n",
    "plt.plot(new_points, betas[0,0] + predictions, '.', c='red')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the following dataset\n",
    "from sklearn.datasets import make_regression # a simpler way to create regression data\n",
    "x, y = make_regression(n_samples=1000, n_features=1, noise=0.2)\n",
    "y = np.power(y,2)\n",
    "plt.plot(x, y, 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix([np.ones(x.shape[0]),x.ravel()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.dot(np.linalg.inv(np.dot(X.T,X)),np.dot(X.T,y).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.arange(-4,4,0.05)\n",
    "predictions = betas[1,0] * new_points\n",
    "plt.plot(x, y, 'x')\n",
    "plt.plot(new_points, betas[0,0] + predictions, '.', c='red')\n",
    "plt.xlim((-4,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* What is the problem of applying linear regression to this dataset?\n",
    "* Can you think of a solution, still using linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Model:\n",
    "\n",
    "$y = b + \\sum_{j=1}^{d}w_j x_j$\n",
    "\n",
    "Closed-form analytic solution (as before, we merge $b$ into $w$):\n",
    "\n",
    "$w = \\Big(X^TX\\Big)^{-1}X^Ty$\n",
    "\n",
    "Stochastic Gradient Descent (SGD), at a given step on a single datapoint $i$:\n",
    "\n",
    "$w \\leftarrow w - \\eta \\Big(\\partial_{w} l^i(y,\\hat{y}) \\Big)$\n",
    "\n",
    "Where:\n",
    "* $\\eta$ is the learning rate\n",
    "* $\\partial_{w}$ is the gradient (derivative) of the loss with respect to the model parameters $w$\n",
    "* $l^i$ is the loss calculated for the training datapoint $i$\n",
    "\n",
    "Remember that we use the squared loss, that for a single data point is defined as (3.1.5): $l^i(y,\\hat{y}) = \\frac{1}{2}\\Big(\\hat{y}^i - y^i\\Big)^2$\n",
    "\n",
    "When we have a *batch* of training data $B$ instead of a single data point, we simply average the gradients (3.1.10):\n",
    "\n",
    "$w \\leftarrow w - \\frac{\\eta}{|B|} \\sum_{i \\in B} \\Big(\\partial_{w} l^i(y,\\hat{y}) \\Big)$\n",
    "\n",
    "At the end, we always use the model on new data points $x$ as follows:\n",
    "\n",
    "$\\hat{y} = w^Tx$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to our example with a single feature plus intercept, and a batch of datapoints $B$, we have the following partial derivatives (3.1.11):\n",
    "\n",
    "$b \\leftarrow b - \\frac{\\eta}{|B|} \\sum_{i \\in B} \\Big( w^Tx^i + b - y^i \\Big)$\n",
    "\n",
    "$w \\leftarrow w - \\frac{\\eta}{|B|} \\sum_{i \\in B} x^i \\Big( w^Tx^i + b - y^i \\Big)$\n",
    "\n",
    "Where $b$ is the coefficient for the intercept, and $w$ for the single feature we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example with the intercept\n",
    "\n",
    "mean = [0, 15] # means (centers of mass)\n",
    "cov = [[5, 0], [120, 100]]  # covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.random.multivariate_normal(mean, cov, 1000, check_valid='ignore').T\n",
    "plt.plot(x, y, 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "beta0 = 0  # Intercept\n",
    "beta1 = 0  # Slope\n",
    "learning_rate = 0.001\n",
    "n_iterations = 100\n",
    "n = len(x)\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "for iteration in range(n_iterations):\n",
    "    shuffled_indices = np.random.permutation(n)\n",
    "    X_shuffled = x[shuffled_indices]\n",
    "    y_shuffled = y[shuffled_indices]\n",
    "    for i in range(n):\n",
    "        xi = X_shuffled[i:i+1]\n",
    "        yi = y_shuffled[i:i+1]\n",
    "        gradients = xi * ((beta1 * xi + beta0) - yi)  # Derivative w.r.t beta1\n",
    "        intercept_gradients = ((beta1 * xi + beta0) - yi)  # Derivative w.r.t beta0\n",
    "        beta1 = beta1 - learning_rate * gradients\n",
    "        beta0 = beta0 - learning_rate * intercept_gradients\n",
    "\n",
    "# The model is y = beta0 + beta1*x\n",
    "print(f\"Model slope (m): {beta1}\")\n",
    "print(f\"Model intercept (b): {beta0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.arange(-40,40,0.5)\n",
    "predictions = beta1 * new_points\n",
    "plt.plot(x, y, 'x')\n",
    "plt.plot(new_points, beta0 + predictions, '.', c='red')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Try to vary the learning rate, what happens?\n",
    "* Try to add one more feature to X, how to do it?\n",
    "* Try to add an outlier, what happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations\n",
    "\n",
    "We will now see an implementation with **sklearn**, and later we will use **pytorch** for the same model.\n",
    "\n",
    "Sklearn provides easy access and a common API to a wealth of ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "x = x.reshape((len(x),1))\n",
    "reg = LinearRegression().fit(x, y)\n",
    "reg.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.arange(-40,40,0.5)\n",
    "new_points = new_points.reshape((len(new_points),1))\n",
    "predictions = reg.predict(new_points)\n",
    "plt.plot(x, y, 'x')\n",
    "plt.plot(new_points, reg.coef_ + predictions, '.', c='red')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Implement the [SGD regression using Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor)\n",
    "* Explore the topic of regularization (book section 3.7) and implement the [L1 (Lasso)](https://scikit-learn.org/stable/modules/linear_model.html#lasso) and [L2 (Ridge)](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification) regression variants\n",
    "* Explore the [Sklearn library](https://scikit-learn.org) and try to use some of its models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example\n",
    "As a working example, we use a dataset of contracts of apprenticeship from early modern Venice. Our goals will be to train a regression model from scratch using this dataset, to better understand the predictors of an apprentice's salary.\n",
    "\n",
    "[See here for more information on this dataset](https://github.com/mromanello/ADA-DHOxSS/tree/master/data#contracts-of-apprenticeship-in-early-modern-venice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"data/apprenticeship_venice/\"\n",
    "df_contracts = pd.read_csv(codecs.open(os.path.join(root_folder,\"professions_data.csv\"), encoding=\"utf8\"), sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contracts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contracts.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every row represents an apprenticeship contract. Contracts were registered both at the guild's and at a public office. This is a sample of contracts from a much larger set of records.\n",
    "\n",
    "Some of the variables we will work with are:\n",
    "* `annual_salary`: the annual salary paid to the apprencice, if any (in Venetian ducats).\n",
    "* `a_profession` to `corporation`: increasingly generic classifications for the apprentice's stated profession.\n",
    "* `startY` and `enrolmentY`: contract start and registration year respectively.\n",
    "* `length`: of the contract, in years.\n",
    "* `m_gender` and `a_gender`: of master and apprentice respectively.\n",
    "* `a_age`: age of the apprentice at entry, in years.\n",
    "* `female_guarantor`: if at least one of the contract's guarantors was female, boolean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "Let us focus on our regression task: predicting the salary of an apprentice given some other features of the contract. We need to select and inspect the variables to use, forming up our domain-specific model. The choice of the features, eventually their filtering and transformations, should be informed by our working hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_contracts.shape[0])\n",
    "\n",
    "# select a few independent variables and drop NA\n",
    "df_contracts = df_contracts.replace([np.inf, -np.inf], np.nan)\n",
    "df_dataset = df_contracts[[\"annual_salary\",\"length\",\"a_age\",\"female_guarantor\",\"salary_master\",\"incremental_salary\"]].dropna()\n",
    "# only pick contracts with a salary paid by the master to the apprentice\n",
    "df_dataset = df_dataset[df_dataset.salary_master == 1]\n",
    "print(df_dataset.shape[0])\n",
    "df_dataset = df_dataset.drop(\"salary_master\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch for correlations, but be wary of very high correlations: they might make the model fitting problematic (this is called 'multicollinearity')\n",
    "\n",
    "sns.pairplot(df_dataset[[\"annual_salary\",\"length\",\"a_age\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "\n",
    "Usually we do not use the closed-form solution to fit a model. We instead rely on existing packages which offer approximate and robust methods to fit a model. It is often a good idea, once the basics are clear, to turn to a more robust implementation.\n",
    "\n",
    "[Statsmodels](https://www.statsmodels.org/stable/index.html) is a Python library exposing a variety of robust modelling solutions for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dependent variable and add intercept\n",
    "\n",
    "y = df_dataset[[\"annual_salary\"]]\n",
    "X = df_dataset.drop(\"annual_salary\",axis=1)\n",
    "X = sm.add_constant(X, prepend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this [guide on how to interpret results](https://www.geeksforgeeks.org/interpreting-the-results-of-linear-regression-using-ols-summary/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
